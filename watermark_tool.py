# -*- coding: utf-8 -*- # Add this for better encoding support
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import gradio as gr
import os
import time
import math
import random
import multiprocessing
from pathlib import Path # For easier path handling

# --- Configuration ---
DEFAULT_FONT_PATH = "ali.ttf" # Example: SimHei, Arial Unicode MS, Noto Sans CJK etc. USER MUST PROVIDE if needed.
DEFAULT_OUTPUT_DIR = "output_videos"

# --- Helper Functions ---

def hex_to_rgba(hex_color, alpha=255):
    """
    Converts hex color string (#RRGGBB or #RGB) to (R, G, B, A) tuple.
    The 'alpha' parameter (0-255) determines the final transparency.
    """
    if not hex_color:
        print("Warning: Color is empty, defaulting to white.")
        hex_color = "#FFFFFF"

    hex_input = hex_color.lstrip('#')

    if not all(c in '0123456789ABCDEFabcdef' for c in hex_input):
         print(f"è­¦å‘Šï¼šæ— æ•ˆçš„åå…­è¿›åˆ¶é¢œè‰²å­—ç¬¦: {hex_color}ï¼Œå°†ä½¿ç”¨ç™½è‰²ã€‚")
         hex_input = "FFFFFF"

    if len(hex_input) == 3:
        hex_input = ''.join([c*2 for c in hex_input])
    elif len(hex_input) != 6:
         print(f"è­¦å‘Šï¼šæ— æ•ˆçš„åå…­è¿›åˆ¶é¢œè‰²é•¿åº¦ (å¿…é¡»æ˜¯ 3 æˆ– 6 ä½): #{hex_input}ï¼Œå°†ä½¿ç”¨ç™½è‰²ã€‚")
         hex_input = "FFFFFF"

    try:
        r = int(hex_input[0:2], 16)
        g = int(hex_input[2:4], 16)
        b = int(hex_input[4:6], 16)
    except ValueError:
        print(f"é”™è¯¯: è½¬æ¢åå…­è¿›åˆ¶é¢œè‰²å¤±è´¥: {hex_color}ï¼Œå°†ä½¿ç”¨ç™½è‰²ã€‚")
        r, g, b = 255, 255, 255

    final_alpha = max(0, min(255, int(alpha)))
    return (r, g, b, final_alpha)

def apply_opacity(img, opacity_percent):
    """Applies overall opacity to a PIL image (RGBA)."""
    if img.mode != 'RGBA':
        img = img.convert('RGBA')
    alpha_channel = img.split()[3]
    opacity_factor = max(0.0, min(1.0, opacity_percent / 100.0))
    new_alpha = alpha_channel.point(lambda p: max(0, min(255, int(p * opacity_factor))))
    img.putalpha(new_alpha)
    return img

# --- Watermark Generation ---

def create_text_watermark(
    text, font_path, font_size, color_hex, opacity_percent,
    stroke_width=0, stroke_color_hex="#000000",
    shadow_offset_x=0, shadow_offset_y=0, shadow_color_hex="#000000"
):
    """Creates a transparent PIL image with styled text (color, opacity, stroke, shadow)."""
    effective_font_path = font_path
    try:
        if not effective_font_path or not os.path.exists(effective_font_path):
             if os.path.exists(DEFAULT_FONT_PATH):
                 print(f"è­¦å‘Š: å­—ä½“æ–‡ä»¶ '{effective_font_path}' æœªæ‰¾åˆ°æˆ–æœªæä¾›ã€‚ä½¿ç”¨é»˜è®¤å­—ä½“: {DEFAULT_FONT_PATH}")
                 effective_font_path = DEFAULT_FONT_PATH
             else:
                 raise ValueError(f"æœªæ‰¾åˆ°å­—ä½“æ–‡ä»¶ '{effective_font_path}' æˆ–é»˜è®¤å­—ä½“ '{DEFAULT_FONT_PATH}'ã€‚è¯·ä¸Šä¼ å­—ä½“æˆ–ç¡®ä¿é»˜è®¤å­—ä½“è·¯å¾„æœ‰æ•ˆã€‚")
        font = ImageFont.truetype(effective_font_path, font_size)
        print(f"ä½¿ç”¨å­—ä½“: {effective_font_path}")
    except IOError as e:
        print(f"é”™è¯¯: åŠ è½½å­—ä½“æ–‡ä»¶æ—¶å‡ºé”™ {effective_font_path}: {e}ã€‚å°è¯• Pillow é»˜è®¤å­—ä½“ã€‚")
        try:
            font = ImageFont.load_default()
        except Exception as e_def:
             raise ValueError(f"æ— æ³•åŠ è½½æŒ‡å®šå­—ä½“ '{effective_font_path}' æˆ– Pillow é»˜è®¤å­—ä½“ã€‚é”™è¯¯: {e_def}")

    # --- Calculate text bounding box and required image size ---
    try:
        # Base alpha calculation (applied to all color components)
        base_alpha = int(255 * (opacity_percent / 100.0))

        # Get base text dimensions
        text_bbox = font.getbbox(text)
        text_width = text_bbox[2] - text_bbox[0]
        text_height = text_bbox[3] - text_bbox[1]
        text_offset_y = -text_bbox[1] # Vertical offset from baseline

        # Calculate maximum offsets needed for stroke and shadow
        max_offset_x = max(0, shadow_offset_x) + stroke_width
        min_offset_x = min(0, shadow_offset_x) - stroke_width
        max_offset_y = max(0, shadow_offset_y) + stroke_width
        min_offset_y = min(0, shadow_offset_y) - stroke_width

        # Calculate final image dimensions including effects
        img_width = text_width + max_offset_x - min_offset_x
        img_height = text_height + max_offset_y - min_offset_y

        # Padding around the effects for safety
        padding = 2 # Minimal padding
        img_width += 2 * padding
        img_height += 2 * padding

        # Determine drawing origin within the padded image
        # Start drawing adjusted by negative offsets and padding
        draw_origin_x = padding - min_offset_x
        draw_origin_y = padding - min_offset_y + text_offset_y # Also include baseline offset

        # Create transparent base image
        img = Image.new('RGBA', (int(img_width), int(img_height)), (255, 255, 255, 0))
        draw = ImageDraw.Draw(img)

        # --- Calculate Colors ---
        text_color_rgba = hex_to_rgba(color_hex, alpha=base_alpha)
        shadow_color_rgba = hex_to_rgba(shadow_color_hex, alpha=base_alpha) if shadow_offset_x != 0 or shadow_offset_y != 0 else None
        stroke_color_rgba = hex_to_rgba(stroke_color_hex, alpha=base_alpha) if stroke_width > 0 else None

        # --- Draw Effects (Order: Shadow -> Stroke -> Fill) ---
        # 1. Draw Shadow (if enabled)
        if shadow_color_rgba:
            shadow_pos = (draw_origin_x + shadow_offset_x, draw_origin_y + shadow_offset_y)
            # Draw shadow without stroke first
            draw.text(shadow_pos, text, font=font, fill=shadow_color_rgba)

        # 2. Draw Main Text (potentially with stroke)
        main_pos = (draw_origin_x, draw_origin_y)
        if stroke_color_rgba and stroke_width > 0:
            # Newer Pillow versions support stroke directly
            try:
                draw.text(
                    main_pos, text, font=font, fill=text_color_rgba,
                    stroke_width=stroke_width, stroke_fill=stroke_color_rgba
                )
            except TypeError: # Older Pillow might not have stroke args
                 print("è­¦å‘Š: å½“å‰ Pillow ç‰ˆæœ¬ä¸æ”¯æŒæè¾¹å‚æ•°ï¼Œå°†è·³è¿‡æè¾¹ã€‚è¯·è€ƒè™‘å‡çº§ Pillowã€‚")
                 draw.text(main_pos, text, font=font, fill=text_color_rgba)
            except Exception as draw_err:
                 print(f"ç»˜åˆ¶å¸¦æè¾¹çš„æ–‡æœ¬æ—¶å‡ºé”™: {draw_err}")
                 draw.text(main_pos, text, font=font, fill=text_color_rgba) # Fallback
        else:
            # Draw text without stroke
            draw.text(main_pos, text, font=font, fill=text_color_rgba)


        # --- Crop to actual content ---
        try:
             bbox = img.getbbox()
             if bbox:
                 img = img.crop(bbox)
             else:
                 print("è­¦å‘Š: æ°´å°å†…å®¹å®Œå…¨é€æ˜æˆ–ä¸ºç©ºï¼Œç”Ÿæˆ 1x1 é€æ˜å›¾åƒã€‚")
                 img = Image.new('RGBA', (1, 1), (255, 255, 255, 0))
        except Exception as crop_e:
             print(f"è­¦å‘Š: è£å‰ªæ–‡æœ¬æ°´å°æ—¶å‡ºé”™: {crop_e}. ä½¿ç”¨æœªè£å‰ªå›¾åƒã€‚")
             pass # Use the padded image if cropping fails

        if img.width <= 0 or img.height <= 0:
             print("è­¦å‘Š: åˆ›å»ºçš„æ–‡æœ¬æ°´å°å°ºå¯¸ä¸ºé›¶æˆ–è´Ÿæ•°ï¼Œå°†ä½¿ç”¨1x1é€æ˜åƒç´ ã€‚")
             img = Image.new('RGBA', (1, 1), (255, 255, 255, 0))

        return img

    except Exception as e:
        print(f"é”™è¯¯: åˆ›å»ºæ–‡æœ¬æ°´å°æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        # Fallback to a minimal transparent image on error
        return Image.new('RGBA', (10, 10), (255, 255, 255, 0))


def load_image_watermark(image_path, scale_percent, frame_width, frame_height, opacity_percent):
    """Loads, scales, and applies opacity to an image watermark."""
    if not image_path or not os.path.exists(image_path):
         raise ValueError(f"å›¾ç‰‡æ°´å°æ–‡ä»¶æœªæ‰¾åˆ°æˆ–æ— æ•ˆ: {image_path}")
    try:
        img = Image.open(image_path).convert("RGBA")
    except Exception as e:
        raise ValueError(f"æ‰“å¼€å›¾ç‰‡æ°´å°æ—¶å‡ºé”™ {image_path}: {e}")

    # Scaling based on frame dimension and percentage
    base_dimension = max(frame_width, frame_height)
    target_width = int(base_dimension * (scale_percent / 100.0))

    if img.width > 0:
        img_ratio = img.height / img.width
        target_height = int(target_width * img_ratio)
    else: target_height = 1 # Avoid zero height

    target_width = max(1, target_width)
    target_height = max(1, target_height)

    try:
        # Use LANCZOS for high-quality resize
        resample_filter = Image.Resampling.LANCZOS if hasattr(Image, 'Resampling') else Image.ANTIALIAS
        img = img.resize((target_width, target_height), resample_filter)
    except Exception as resize_e:
         raise ValueError(f"ç¼©æ”¾å›¾ç‰‡æ°´å°æ—¶å‡ºé”™: {resize_e}")

    # Apply Opacity
    img = apply_opacity(img, opacity_percent)
    return img


# --- Motion Calculation (WatermarkMover class remains largely the same) ---
class WatermarkMover:
    """è®¡ç®—æ°´å°ä½ç½®åŸºäºé€‰å®šçš„è·¯å¾„å’ŒåŒºåŸŸã€‚"""
    def __init__(self, path_type, frame_width, frame_height, watermark_width, watermark_height, margin_percent, speed_factor):
        self.path_type = path_type
        self.speed_factor = max(0.1, speed_factor)

        margin_x = int(frame_width * (margin_percent / 100.0))
        margin_y = int(frame_height * (margin_percent / 100.0))

        self.min_x = margin_x
        self.min_y = margin_y
        self.max_x = frame_width - margin_x - watermark_width
        self.max_y = frame_height - margin_y - watermark_height

        self.max_x = max(self.min_x, self.max_x) # Ensure bounds are valid
        self.max_y = max(self.min_y, self.max_y)

        self.frame_width = frame_width
        self.frame_height = frame_height
        self.watermark_width = watermark_width
        self.watermark_height = watermark_height
        self.margin_percent = margin_percent
        self.total_frames_hint = 1 # Used for cycle calculation if needed

        # Initial state for dynamic paths
        self.x = random.randint(self.min_x, self.max_x) if self.max_x > self.min_x else self.min_x
        self.y = random.randint(self.min_y, self.max_y) if self.max_y > self.min_y else self.min_y

        base_speed_x = max(1, int(frame_width * 0.005 * self.speed_factor))
        base_speed_y = max(1, int(frame_height * 0.005 * self.speed_factor))

        self.dx = random.choice([-base_speed_x, base_speed_x]) if self.max_x > self.min_x else 0
        self.dy = random.choice([-base_speed_y, base_speed_y]) if self.max_y > self.min_y else 0

        if self.dx == 0 and self.dy == 0 and (self.max_x > self.min_x or self.max_y > self.min_y):
             self.dx = base_speed_x if self.max_x > self.min_x else 0
             self.dy = base_speed_y if self.max_y > self.min_y and self.dx == 0 else 0

        self.static_x = max(0, (frame_width - watermark_width) // 2)
        self.static_y = max(0, (frame_height - watermark_height) // 2)

    def update_total_frames(self, total_frames):
        """Allow updating total frames if known late."""
        self.total_frames_hint = max(1, total_frames)

    def get_position(self, frame_index):
        """è®¡ç®—å½“å‰å¸§çš„ä½ç½®ã€‚"""
        total_frames = self.total_frames_hint # Use the stored total frames
        if self.path_type == "é™æ€å±…ä¸­":
            return self.static_x, self.static_y

        elif self.path_type == "è¾¹æ¡†åå¼¹":
            if self.max_x <= self.min_x: self.dx = 0
            if self.max_y <= self.min_y: self.dy = 0

            self.x += self.dx
            self.y += self.dy

            bounced = False
            if self.x <= self.min_x:
                self.x = self.min_x
                self.dx = abs(self.dx) if self.dx != 0 else (random.randint(1, max(1, int(self.frame_width * 0.005 * self.speed_factor)))) if self.max_x > self.min_x else 0
                bounced = True
            elif self.x >= self.max_x:
                self.x = self.max_x
                self.dx = -abs(self.dx) if self.dx != 0 else (-random.randint(1, max(1, int(self.frame_width * 0.005 * self.speed_factor)))) if self.max_x > self.min_x else 0
                bounced = True

            if self.y <= self.min_y:
                self.y = self.min_y
                self.dy = abs(self.dy) if self.dy != 0 else (random.randint(1, max(1, int(self.frame_height * 0.005 * self.speed_factor)))) if self.max_y > self.min_y else 0
                bounced = True
            elif self.y >= self.max_y:
                self.y = self.max_y
                self.dy = -abs(self.dy) if self.dy != 0 else (-random.randint(1, max(1, int(self.frame_height * 0.005 * self.speed_factor)))) if self.max_y > self.min_y else 0
                bounced = True

            self.x = max(self.min_x, min(self.x, self.max_x))
            self.y = max(self.min_y, min(self.y, self.max_y))

            return int(self.x), int(self.y)

        elif self.path_type == "æ°´å¹³ç§»åŠ¨":
            progress = (frame_index % total_frames) / total_frames
            amplitude = max(0, (self.max_x - self.min_x) / 2)
            center_x = self.min_x + amplitude
            frequency = 1.0 * self.speed_factor
            current_x = center_x + amplitude * math.sin(2 * math.pi * frequency * progress)
            current_y = self.min_y + max(0, (self.max_y - self.min_y) / 2)
            return int(max(self.min_x, min(current_x, self.max_x))), int(current_y)

        elif self.path_type == "å‚ç›´ç§»åŠ¨":
            progress = (frame_index % total_frames) / total_frames
            amplitude = max(0, (self.max_y - self.min_y) / 2)
            center_y = self.min_y + amplitude
            frequency = 1.0 * self.speed_factor
            current_y = center_y + amplitude * math.sin(2 * math.pi * frequency * progress)
            current_x = self.min_x + max(0, (self.max_x - self.min_x) / 2)
            return int(current_x), int(max(self.min_y, min(current_y, self.max_y)))

        else:
            print(f"è­¦å‘Š: æœªçŸ¥çš„ç§»åŠ¨è·¯å¾„ '{self.path_type}'ï¼Œå°†ä½¿ç”¨é™æ€å±…ä¸­ã€‚")
            return self.static_x, self.static_y


# --- Core Video Processing ---

def add_watermark_to_video(input_video_path, output_video_path, watermark_pil, mover):
    """å°†å‡†å¤‡å¥½çš„æ°´å° PIL å›¾åƒæ·»åŠ åˆ°è§†é¢‘çš„æ¯ä¸€å¸§ã€‚ (No Gradio Progress here)"""
    cap = cv2.VideoCapture(str(input_video_path)) # Use string path
    if not cap.isOpened():
        raise IOError(f"é”™è¯¯: æ‰“å¼€è§†é¢‘æ–‡ä»¶å¤±è´¥: {input_video_path}")

    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    if not all([fps > 0, frame_width > 0, frame_height > 0, total_frames >= 0]):
         cap.release()
         raise ValueError(f"è§†é¢‘å±æ€§æ— æ•ˆ: FPS={fps}, W={frame_width}, H={frame_height}, Frames={total_frames}")

    # Update mover with actual total frames if available
    mover.update_total_frames(total_frames)

    # Ensure watermark fits (resize if necessary) - Should be done *before* mover init usually,
    # but mover is already initialized. If we resize here, bounds *might* be slightly off
    # if the watermark was initially too large. Ideally, resize happens before mover creation.
    # Let's assume watermark passed is already appropriately sized (handled in worker).

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(str(output_video_path), fourcc, fps, (frame_width, frame_height)) # Use string path
    if not out.isOpened():
        cap.release()
        raise IOError(f"é”™è¯¯: æ— æ³•åˆ›å»ºè¾“å‡ºè§†é¢‘æ–‡ä»¶: {output_video_path}")

    frame_count = 0
    start_time = time.time()
    log_interval = max(1, int(fps * 5)) # Log every 5 seconds approx

    # Pre-check if watermark has any non-transparent pixels
    has_visible_watermark = False
    if watermark_pil.mode == 'RGBA':
        alpha_min, alpha_max = watermark_pil.getextrema()[3]
        if alpha_max > 0: # Check if maximum alpha is greater than 0
             has_visible_watermark = True
    else: # If not RGBA, assume it's visible
         has_visible_watermark = True

    while True:
        ret, frame_bgr = cap.read()
        if not ret:
            break

        if has_visible_watermark:
            try:
                frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
                pil_frame = Image.fromarray(frame_rgb).convert("RGBA")

                wm_x, wm_y = mover.get_position(frame_count)
                wm_x = max(0, min(int(wm_x), frame_width - watermark_pil.width))
                wm_y = max(0, min(int(wm_y), frame_height - watermark_pil.height))

                # Optimized pasting: Avoid creating full overlay if possible
                # Paste directly onto the frame copy using the mask
                pil_frame.paste(watermark_pil, (wm_x, wm_y), mask=watermark_pil)

                pil_frame_out_rgb = pil_frame.convert("RGB")
                frame_out_bgr = cv2.cvtColor(np.array(pil_frame_out_rgb), cv2.COLOR_RGB2BGR)

                out.write(frame_out_bgr)

            except Exception as e:
                print(f"é”™è¯¯: åœ¨å¸§ {frame_count} å¤„ç†æ°´å°æ—¶å‡ºé”™: {e}. å†™å…¥åŸå§‹å¸§ã€‚")
                out.write(frame_bgr) # Write original frame on error
        else:
             # If watermark is fully transparent, just write the original frame
             out.write(frame_bgr)


        frame_count += 1
        if frame_count % log_interval == 0:
             elapsed = time.time() - start_time
             rate = frame_count / elapsed if elapsed > 0 else 0
             print(f"  æ–‡ä»¶ {Path(input_video_path).name}: å·²å¤„ç† {frame_count} / {total_frames if total_frames > 0 else '?'} å¸§ ({rate:.1f} fps)")

    cap.release()
    out.release()

    end_time = time.time()
    duration = end_time - start_time
    print(f"å®Œæˆå¤„ç† {Path(input_video_path).name}ã€‚è€—æ—¶: {duration:.2f} ç§’")


# --- Multiprocessing Worker Function ---

def process_single_video_worker(args):
    """Worker function to process one video file."""
    (
        input_path_str, output_dir_str, watermark_params, motion_params, common_params
    ) = args

    input_path = Path(input_path_str)
    output_dir = Path(output_dir_str)
    base_filename = input_path.stem
    safe_filename_base = "".join(c if c.isalnum() or c in ('_', '-') else '_' for c in base_filename) + "_watermarked"
    output_ext = ".mp4"

    # --- Unique Filename Logic ---
    output_path = output_dir / f"{safe_filename_base}{output_ext}"
    counter = 1
    while output_path.exists():
        output_path = output_dir / f"{safe_filename_base}_{counter}{output_ext}"
        counter += 1
    # --- End Unique Filename Logic ---

    status_message = f"å¼€å§‹å¤„ç†: {input_path.name} -> {output_path.name}\n"
    print(status_message.strip()) # Log start to console

    try:
        # --- Get Video Dimensions ---
        temp_cap = cv2.VideoCapture(str(input_path))
        if not temp_cap.isOpened():
            raise IOError(f"æ— æ³•æ‰“å¼€è§†é¢‘ '{input_path.name}' ä»¥è·å–å°ºå¯¸ã€‚")
        vid_width = int(temp_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        vid_height = int(temp_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        # total_vid_frames = int(temp_cap.get(cv2.CAP_PROP_FRAME_COUNT)) # Get total frames for mover
        temp_cap.release()
        if vid_width <= 0 or vid_height <= 0:
             raise ValueError(f"è·å–åˆ°çš„è§†é¢‘å°ºå¯¸æ— æ•ˆ: {vid_width}x{vid_height}")
        status_message += f"  è§†é¢‘å°ºå¯¸: {vid_width}x{vid_height}\n"

        # --- Prepare Watermark ---
        watermark_pil = None
        watermark_type = common_params['watermark_type']
        opacity = common_params['watermark_opacity']

        if watermark_type == "æ–‡æœ¬":
            # Unpack text params
            wp = watermark_params # shortcut
            status_message += f"  åˆ›å»ºæ–‡æœ¬æ°´å°: '{wp['text_content'][:30]}...' å°ºå¯¸:{wp['font_size']}pt Opacity:{opacity}%\n"
            watermark_pil = create_text_watermark(
                text=wp['text_content'], font_path=wp['font_path'], font_size=wp['font_size'], color_hex=wp['text_color'],
                opacity_percent=opacity,
                stroke_width=wp['stroke_width'], stroke_color_hex=wp['stroke_color'],
                shadow_offset_x=wp['shadow_offset_x'], shadow_offset_y=wp['shadow_offset_y'], shadow_color_hex=wp['shadow_color']
            )
        elif watermark_type == "å›¾ç‰‡":
            # Unpack image params
            ip = watermark_params # shortcut
            status_message += f"  åŠ è½½å›¾ç‰‡æ°´å°: ç¼©æ”¾:{ip['image_scale']}% Opacity:{opacity}%\n"
            watermark_pil = load_image_watermark(
                ip['image_path'], ip['image_scale'], vid_width, vid_height, opacity
            )
        else:
            raise ValueError(f"æœªçŸ¥çš„å†…éƒ¨æ°´å°ç±»å‹ '{watermark_type}'")

        if watermark_pil is None or watermark_pil.width <= 0 or watermark_pil.height <= 0:
            raise ValueError("æ°´å°åˆ›å»ºå¤±è´¥æˆ–å°ºå¯¸æ— æ•ˆã€‚")
        status_message += f"  æ°´å°å·²ç”Ÿæˆï¼Œå°ºå¯¸: {watermark_pil.width}x{watermark_pil.height}\n"

        # --- Resize watermark if it's larger than frame (rare case after scaling, but safety check) ---
        if watermark_pil.width > vid_width or watermark_pil.height > vid_height:
             print(f"è­¦å‘Š: æ°´å°å°ºå¯¸ ({watermark_pil.width}x{watermark_pil.height}) è¶…å‡ºå¸§å°ºå¯¸ ({vid_width}x{vid_height})ã€‚å°†è°ƒæ•´æ°´å°å¤§å°ä»¥é€‚åº”ã€‚")
             ratio = min(vid_width / watermark_pil.width, vid_height / watermark_pil.height)
             new_w = max(1, int(watermark_pil.width * ratio))
             new_h = max(1, int(watermark_pil.height * ratio))
             try:
                 resample_filter = Image.Resampling.LANCZOS if hasattr(Image, 'Resampling') else Image.ANTIALIAS
                 watermark_pil = watermark_pil.resize((new_w, new_h), resample_filter)
                 status_message += f"  æ°´å°å·²è°ƒæ•´å¤§å°ä¸º: {new_w}x{new_h}\n"
             except Exception as resize_err:
                 status_message += f"  è­¦å‘Š: è°ƒæ•´æ°´å°å¤§å°æ—¶å‡ºé”™: {resize_err}ã€‚\n"
                 # Continue with potentially clipped watermark


        # --- Initialize Mover ---
        mp = motion_params # shortcut
        mover = WatermarkMover(
            path_type=mp['motion_path'], frame_width=vid_width, frame_height=vid_height,
            watermark_width=watermark_pil.width, watermark_height=watermark_pil.height,
            margin_percent=mp['motion_margin'], speed_factor=mp['motion_speed']
        )
        status_message += f"  åˆå§‹åŒ–ç§»åŠ¨å™¨: ç±»å‹:{mp['motion_path']}, è¾¹è·:{mp['motion_margin']}%, é€Ÿåº¦:{mp['motion_speed']}x\n"

        # --- Add Watermark to Video ---
        add_watermark_to_video(input_path, output_path, watermark_pil, mover)

        status_message += f"  æˆåŠŸå¤„ç†å¹¶ä¿å­˜åˆ°: {output_path}\n"
        return status_message, str(output_path) # Return success message and path

    except Exception as e:
        error_msg = f"é”™è¯¯ å¤„ç† {input_path.name} æ—¶å‘ç”Ÿé”™è¯¯: {type(e).__name__}: {e}\n"
        print(f"!!! {error_msg.strip()}") # Log full error to console
        status_message += error_msg
        # Clean up partially created output file if it exists
        if output_path.exists():
             try:
                 output_path.unlink()
                 status_message += f"  å·²åˆ é™¤éƒ¨åˆ†ç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶: {output_path.name}\n"
             except OSError as rm_err:
                 status_message += f"  è­¦å‘Š: æ— æ³•åˆ é™¤éƒ¨åˆ†æ–‡ä»¶ {output_path.name}: {rm_err}\n"
        return status_message, None # Return error message and None path


# --- Gradio Interface Function ---

def process_videos_interface(
    input_videos, # List of file paths from gr.Files
    watermark_type,
    # Text params
    text_content, font_file, font_size, text_color,
    stroke_width, stroke_color, shadow_offset_x, shadow_offset_y, shadow_color,
    # Image params
    image_file, image_scale,
    # Common params
    watermark_opacity,
    # Motion params
    motion_path, motion_margin, motion_speed,
    # Output params
    output_dir_name,
    progress=gr.Progress(track_tqdm=True)): # Gradio progress

    if not input_videos:
        return "é”™è¯¯: æœªé€‰æ‹©ä»»ä½•è¾“å…¥è§†é¢‘æ–‡ä»¶ã€‚", [], None

    output_base = Path(output_dir_name if output_dir_name else DEFAULT_OUTPUT_DIR)
    try:
        output_base.mkdir(parents=True, exist_ok=True)
        print(f"è¾“å‡ºç›®å½•: {output_base.resolve()}")
    except OSError as e:
        return f"é”™è¯¯: æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½• '{output_base}': {e}", [], None

    # --- Prepare Parameters ---
    status_messages = ["å‚æ•°å‡†å¤‡ä¸­..."]
    final_font_path = None
    watermark_params = {}
    common_params = {
        'watermark_type': watermark_type,
        'watermark_opacity': watermark_opacity,
    }

    # --- Font File Handling ---
    if watermark_type == "æ–‡æœ¬":
        if font_file is not None:
            final_font_path = font_file.name # Path from Gradio TempFile
            if not Path(final_font_path).exists():
                 status_messages.append(f"è­¦å‘Š: ä¸Šä¼ çš„å­—ä½“æ–‡ä»¶è·¯å¾„ '{final_font_path}' æ— æ•ˆã€‚å°è¯•ä½¿ç”¨é»˜è®¤å­—ä½“ã€‚")
                 final_font_path = None
            else:
                 status_messages.append(f"ä½¿ç”¨ä¸Šä¼ çš„å­—ä½“: {Path(final_font_path).name}")
        else:
            status_messages.append(f"æœªæä¾›å­—ä½“æ–‡ä»¶ã€‚å°è¯•ä½¿ç”¨é»˜è®¤å­—ä½“: {DEFAULT_FONT_PATH}")

        if final_font_path is None:
             if Path(DEFAULT_FONT_PATH).exists():
                 final_font_path = DEFAULT_FONT_PATH
                 status_messages.append(f"ä½¿ç”¨é»˜è®¤å­—ä½“: {DEFAULT_FONT_PATH}")
             else:
                 error_msg = f"é”™è¯¯: æ–‡æœ¬æ°´å°éœ€è¦å­—ä½“ï¼Œä½†æ—¢æœªæä¾›æœ‰æ•ˆå­—ä½“ï¼Œä¹Ÿæ‰¾ä¸åˆ°é»˜è®¤å­—ä½“ '{DEFAULT_FONT_PATH}'ã€‚"
                 status_messages.append(error_msg)
                 return "\n".join(status_messages), [], None

        watermark_params = {
            'text_content': text_content, 'font_path': final_font_path, 'font_size': font_size, 'text_color': text_color,
            'stroke_width': stroke_width, 'stroke_color': stroke_color,
            'shadow_offset_x': shadow_offset_x, 'shadow_offset_y': shadow_offset_y, 'shadow_color': shadow_color,
        }
    # --- Image File Handling ---
    elif watermark_type == "å›¾ç‰‡":
        if image_file is not None:
            image_watermark_path = image_file.name # Path from Gradio TempFile
            if not Path(image_watermark_path).exists():
                 status_messages.append(f"é”™è¯¯: ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶è·¯å¾„ '{image_watermark_path}' æ— æ•ˆã€‚")
                 return "\n".join(status_messages), [], None
            else:
                 status_messages.append(f"ä½¿ç”¨ä¸Šä¼ çš„å›¾ç‰‡: {Path(image_watermark_path).name}")
                 watermark_params = {'image_path': image_watermark_path, 'image_scale': image_scale}
        else:
             status_messages.append(f"é”™è¯¯: é€‰æ‹©äº†å›¾ç‰‡æ°´å°ç±»å‹ï¼Œä½†æœªæä¾›å›¾ç‰‡æ–‡ä»¶ã€‚")
             return "\n".join(status_messages), [], None

    motion_params = {
        'motion_path': motion_path, 'motion_margin': motion_margin, 'motion_speed': motion_speed,
    }

    # --- Prepare Arguments for Workers ---
    task_args = []
    for video_file in input_videos:
        input_path_str = video_file.name # Get path from Gradio file object
        task_args.append((
            input_path_str, str(output_base), watermark_params, motion_params, common_params
        ))

    # --- Process Using Multiprocessing Pool ---
    num_workers = os.cpu_count()
    status_messages.append(f"\nå¼€å§‹ä½¿ç”¨ {num_workers} ä¸ª CPU æ ¸å¿ƒå¤„ç† {len(task_args)} ä¸ªè§†é¢‘...")
    print(f"å¼€å§‹ä½¿ç”¨ {num_workers} ä¸ª CPU æ ¸å¿ƒå¤„ç† {len(task_args)} ä¸ªè§†é¢‘...")

    output_file_paths = []
    processed_count = 0
    total_videos = len(task_args)

    # Use try-finally to ensure pool cleanup
    pool = None
    try:
        # Use context manager for pool if Python >= 3.3
        # with multiprocessing.Pool(processes=num_workers) as pool:
        pool = multiprocessing.Pool(processes=num_workers)
        # Use imap_unordered to get results as they complete for better progress feedback
        results_iterator = pool.imap_unordered(process_single_video_worker, task_args)

        # Update progress as each video finishes
        for result in results_iterator:
            processed_count += 1
            message, output_path = result
            status_messages.append(f"\n--- ç»“æœ ({processed_count}/{total_videos}) ---")
            status_messages.append(message.strip())
            if output_path:
                output_file_paths.append(output_path)

            # Update Gradio progress bar
            progress(processed_count / total_videos, desc=f"å·²å¤„ç† {processed_count}/{total_videos} ä¸ªè§†é¢‘")

        pool.close()
        pool.join()

    except Exception as pool_err:
        error_msg = f"!!! å¤šè¿›ç¨‹å¤„ç†æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {pool_err}"
        print(error_msg)
        status_messages.append(error_msg)
    finally:
        if pool:
            pool.terminate() # Force terminate if something went wrong

    status_messages.append("\næ‰¹é‡å¤„ç†å®Œæˆã€‚")
    final_status = "\n".join(status_messages)
    print("æ‰¹é‡å¤„ç†å®Œæˆã€‚")

    # Return status log, list of output file paths, and None for preview
    return final_status, output_file_paths, None


# --- Preview Function ---
def generate_preview(
    input_videos, # Need this to get a frame
    watermark_type,
    # Text params
    text_content, font_file, font_size, text_color,
    stroke_width, stroke_color, shadow_offset_x, shadow_offset_y, shadow_color,
    # Image params
    image_file, image_scale,
    # Common params
    watermark_opacity,
    # Motion params
    motion_path, motion_margin, motion_speed):

    if not input_videos:
        img = Image.new('RGB', (300, 100), color = 'black')
        d = ImageDraw.Draw(img)
        try: font = ImageFont.truetype("arial.ttf", 15)
        except IOError: font = ImageFont.load_default()
        d.text((10,10), "è¯·å…ˆä¸Šä¼ ä¸€ä¸ªè§†é¢‘æ–‡ä»¶\næ‰èƒ½ç”Ÿæˆé¢„è§ˆ", fill='white', font=font)
        return img

    preview_status = ""
    try:
        input_path = Path(input_videos[0].name) # Use the first video
        preview_status += f"ä½¿ç”¨è§†é¢‘ '{input_path.name}' çš„ä¸€å¸§è¿›è¡Œé¢„è§ˆã€‚\n"

        cap = cv2.VideoCapture(str(input_path))
        if not cap.isOpened():
            raise IOError(f"æ— æ³•æ‰“å¼€è§†é¢‘ '{input_path.name}' è¿›è¡Œé¢„è§ˆã€‚")

        frame_to_preview = 10 # Try a slightly later frame
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_to_preview)
        ret, frame_bgr = cap.read()
        if not ret:
             cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
             ret, frame_bgr = cap.read()
             if not ret: raise ValueError("æ— æ³•è¯»å–è§†é¢‘å¸§è¿›è¡Œé¢„è§ˆã€‚")
             frame_to_preview = 0

        vid_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        vid_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        cap.release()
        if vid_width <= 0 or vid_height <= 0: raise ValueError("é¢„è§ˆæ—¶è§†é¢‘å°ºå¯¸æ— æ•ˆã€‚")

        # --- Prepare Watermark ---
        watermark_pil = None
        final_font_path_preview = None
        if watermark_type == "æ–‡æœ¬":
            # Font path logic for preview
            if font_file is not None and Path(font_file.name).exists():
                 final_font_path_preview = font_file.name
            elif Path(DEFAULT_FONT_PATH).exists():
                 final_font_path_preview = DEFAULT_FONT_PATH
            if final_font_path_preview is None:
                 raise ValueError("é¢„è§ˆéœ€è¦å­—ä½“ï¼Œä½†æœªæä¾›æˆ–æ‰¾ä¸åˆ°é»˜è®¤å­—ä½“ã€‚")

            watermark_pil = create_text_watermark(
                text=text_content, font_path=final_font_path_preview, font_size=font_size, color_hex=text_color,
                opacity_percent=watermark_opacity,
                stroke_width=stroke_width, stroke_color_hex=stroke_color,
                shadow_offset_x=shadow_offset_x, shadow_offset_y=shadow_offset_y, shadow_color_hex=shadow_color
            )
            preview_status += f"åˆ›å»ºæ–‡æœ¬æ°´å° (å­—ä½“: {Path(final_font_path_preview).name}, å°ºå¯¸: {font_size}pt, Opacity: {watermark_opacity}%)\n"

        elif watermark_type == "å›¾ç‰‡":
            if image_file is None or not Path(image_file.name).exists():
                raise ValueError("é¢„è§ˆéœ€è¦å›¾ç‰‡ï¼Œä½†æœªæä¾›æˆ–æ–‡ä»¶æ— æ•ˆã€‚")
            image_watermark_path_preview = image_file.name
            watermark_pil = load_image_watermark(
                image_watermark_path_preview, image_scale, vid_width, vid_height, watermark_opacity
            )
            preview_status += f"åŠ è½½å›¾ç‰‡æ°´å° (æ–‡ä»¶: {Path(image_watermark_path_preview).name}, ç¼©æ”¾: {image_scale}%, Opacity: {watermark_opacity}%)\n"
        else:
             raise ValueError("æ— æ•ˆçš„æ°´å°ç±»å‹ã€‚")

        if watermark_pil is None or watermark_pil.width <= 0 or watermark_pil.height <= 0:
             raise ValueError("é¢„è§ˆæ—¶æ°´å°åˆ›å»ºå¤±è´¥æˆ–å°ºå¯¸æ— æ•ˆã€‚")
        preview_status += f"æ°´å°å°ºå¯¸: {watermark_pil.width}x{watermark_pil.height}\n"

        # --- Initialize Mover ---
        mover = WatermarkMover(
            path_type=motion_path, frame_width=vid_width, frame_height=vid_height,
            watermark_width=watermark_pil.width, watermark_height=watermark_pil.height,
            margin_percent=motion_margin, speed_factor=motion_speed
        )
        mover.update_total_frames(total_frames) # Give mover frame count hint

        # --- Get Position & Composite ---
        wm_x, wm_y = mover.get_position(frame_to_preview)
        wm_x = max(0, min(int(wm_x), vid_width - watermark_pil.width))
        wm_y = max(0, min(int(wm_y), vid_height - watermark_pil.height))
        preview_status += f"æ°´å°ä½ç½® (å¸§ {frame_to_preview}): ({wm_x}, {wm_y})\n"

        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
        pil_frame = Image.fromarray(frame_rgb).convert("RGBA")

        # Composite (using paste with mask)
        if watermark_pil.mode == 'RGBA' and watermark_pil.getextrema()[3][1] > 0: # Check if alpha max > 0
            pil_frame.paste(watermark_pil, (wm_x, wm_y), mask=watermark_pil)
        elif watermark_pil.mode != 'RGBA': # Assume opaque if not RGBA
            pil_frame.paste(watermark_pil, (wm_x, wm_y))


        preview_status += "é¢„è§ˆå›¾ç”ŸæˆæˆåŠŸã€‚"
        print(preview_status)
        return pil_frame.convert("RGB")

    except Exception as e:
        error_msg = f"ç”Ÿæˆé¢„è§ˆæ—¶å‡ºé”™: {type(e).__name__}: {e}"
        print(error_msg)
        img = Image.new('RGB', (400, 150), color = 'darkred')
        d = ImageDraw.Draw(img)
        try: font = ImageFont.truetype("arial.ttf", 15)
        except IOError: font = ImageFont.load_default()
        # Wrap text
        import textwrap
        lines = textwrap.wrap(f"ç”Ÿæˆé¢„è§ˆå¤±è´¥:\n{error_msg}", width=50)
        y_text = 10
        for line in lines:
            width, height = font.getsize(line) if hasattr(font, 'getsize') else (10*len(line), 15) # Basic fallback
            d.text((10, y_text), line, font=font, fill='white')
            y_text += height + 2 # Move y down for next line
        # d.text((10,10), f"ç”Ÿæˆé¢„è§ˆå¤±è´¥:\n{error_msg}", fill='white', font=font)
        return img


# --- Build Gradio UI ---

# Check default font existence early
default_font_exists = Path(DEFAULT_FONT_PATH).exists()
default_font_warning = f" (é»˜è®¤: {Path(DEFAULT_FONT_PATH).name}{'' if default_font_exists else ' - æœªæ‰¾åˆ°!'})"

with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¬ è§†é¢‘æ°´å°æ·»åŠ å·¥å…· (å¢å¼ºç‰ˆ)")
    gr.Markdown("ä¸ºè§†é¢‘æ·»åŠ åŠ¨æ€æ–‡æœ¬æˆ–å›¾ç‰‡æ°´å°ã€‚æ”¯æŒæ–‡æœ¬æè¾¹/é˜´å½±ã€æ–‡ä»¶åé˜²è¦†ç›–ã€å¤šæ ¸å¤„ç†åŠ é€Ÿã€‚")

    with gr.Row():
        with gr.Column(scale=3): # Input settings column slightly wider
            gr.Markdown("### 1. è¾“å…¥è§†é¢‘")
            input_videos = gr.Files(label="ä¸Šä¼ è§†é¢‘æ–‡ä»¶ (å¯å¤šé€‰)", file_types=['video'], type="filepath") # Use filepath

            gr.Markdown("### 2. æ°´å°è®¾ç½®")
            watermark_type = gr.Radio(["æ–‡æœ¬", "å›¾ç‰‡"], label="æ°´å°ç±»å‹", value="æ–‡æœ¬")

            # --- Common Settings ---
            watermark_opacity = gr.Slider(label="æ°´å°ä¸é€æ˜åº¦ (%)", minimum=0, maximum=100, value=70, step=1)

            # --- Text Options ---
            with gr.Group(visible=True) as text_options:
                gr.Markdown("#### æ–‡æœ¬æ°´å°é€‰é¡¹")
                text_content = gr.Textbox(label="æ°´å°æ–‡å­—", value="åœ¨æ­¤è¾“å…¥æ°´å°å†…å®¹", lines=2)
                font_file = gr.File(label=f"ä¸Šä¼ å­—ä½“æ–‡ä»¶ (.ttf, .otf) {default_font_warning}", file_types=['.ttf', '.otf'], type="filepath") # Use filepath
                font_size = gr.Slider(label="å­—ä½“å¤§å° (pt)", minimum=8, maximum=300, value=48, step=1)
                text_color = gr.ColorPicker(label="æ–‡å­—é¢œè‰² (Hex)", value="#FFFFFF")
                with gr.Accordion("æè¾¹ & é˜´å½± (å¯é€‰)", open=False):
                    stroke_width = gr.Slider(label="æè¾¹å®½åº¦ (px)", minimum=0, maximum=10, value=0, step=1)
                    stroke_color = gr.ColorPicker(label="æè¾¹é¢œè‰²", value="#000000")
                    gr.Markdown("---")
                    shadow_offset_x = gr.Slider(label="é˜´å½± X åç§» (px)", minimum=-10, maximum=10, value=0, step=1)
                    shadow_offset_y = gr.Slider(label="é˜´å½± Y åç§» (px)", minimum=-10, maximum=10, value=0, step=1)
                    shadow_color = gr.ColorPicker(label="é˜´å½±é¢œè‰²", value="#000000")


            # --- Image Options ---
            with gr.Group(visible=False) as image_options:
                 gr.Markdown("#### å›¾ç‰‡æ°´å°é€‰é¡¹")
                 image_file = gr.File(label="ä¸Šä¼ æ°´å°å›¾ç‰‡", file_types=['image'], type="filepath") # Use filepath
                 image_scale = gr.Slider(label="å›¾ç‰‡ç¼©æ”¾æ¯”ä¾‹ (%) - ç›¸å¯¹äºè§†é¢‘æœ€å¤§è¾¹é•¿", minimum=1, maximum=50, value=10, step=1)

            # --- Motion Settings ---
            gr.Markdown("### 3. è¿åŠ¨è®¾ç½®")
            motion_path = gr.Dropdown(
                ["é™æ€å±…ä¸­", "è¾¹æ¡†åå¼¹", "æ°´å¹³ç§»åŠ¨", "å‚ç›´ç§»åŠ¨"],
                label="æ°´å°è¿åŠ¨è·¯å¾„", value="è¾¹æ¡†åå¼¹"
            )
            motion_margin = gr.Slider(
                label="è¿åŠ¨åŒºåŸŸè¾¹è· (%)", minimum=0, maximum=45, value=5, step=1
            )
            motion_speed = gr.Slider(
                label="è¿åŠ¨é€Ÿåº¦å€ç‡", minimum=0.1, maximum=10.0, value=1.0, step=0.1
            )

            # --- Output Settings ---
            gr.Markdown("### 4. è¾“å‡ºè®¾ç½®")
            output_dir_name = gr.Textbox(label="è¾“å‡ºå­ç›®å½•åç§°", value=DEFAULT_OUTPUT_DIR)

        with gr.Column(scale=2): # Preview/Action column
            gr.Markdown("### 5. æ°´å°é¢„è§ˆ")
            preview_button = gr.Button("ç”Ÿæˆé¢„è§ˆ (ä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘)")
            preview_output = gr.Image(label="æ•ˆæœé¢„è§ˆ", type="pil", interactive=False)

            gr.Markdown("### 6. å¼€å§‹å¤„ç†")
            process_button = gr.Button("ğŸš€ å¼€å§‹æ·»åŠ æ°´å° (å¤šæ ¸å¤„ç†)", variant="primary")

            gr.Markdown("### çŠ¶æ€æ—¥å¿—")
            status_output = gr.Textbox(label="è¿è¡Œæ—¥å¿—", lines=15, interactive=False, autoscroll=True)

            gr.Markdown("### è¾“å‡ºæ–‡ä»¶")
            output_files_display = gr.Files(label="ç”Ÿæˆçš„æ°´å°è§†é¢‘", interactive=False)


    # --- UI Logic ---
    def update_visibility(choice):
        is_text = (choice == "æ–‡æœ¬")
        return {
            text_options: gr.update(visible=is_text),
            image_options: gr.update(visible=not is_text),
        }
    watermark_type.change(update_visibility, inputs=watermark_type, outputs=[text_options, image_options])

    # Gather all inputs needed for preview and processing
    proc_inputs = [
            input_videos, watermark_type,
            # Text
            text_content, font_file, font_size, text_color,
            stroke_width, stroke_color, shadow_offset_x, shadow_offset_y, shadow_color,
            # Image
            image_file, image_scale,
            # Common
            watermark_opacity,
            # Motion
            motion_path, motion_margin, motion_speed,
            # Output
            output_dir_name
    ]
    preview_inputs = [ # Preview doesn't need output_dir_name
            input_videos, watermark_type,
            # Text
            text_content, font_file, font_size, text_color,
            stroke_width, stroke_color, shadow_offset_x, shadow_offset_y, shadow_color,
            # Image
            image_file, image_scale,
            # Common
            watermark_opacity,
            # Motion
            motion_path, motion_margin, motion_speed,
    ]

    # Connect Preview Button
    preview_button.click(
        fn=generate_preview,
        inputs=preview_inputs,
        outputs=[preview_output]
    )

    # Connect Process Button
    process_button.click(
        fn=process_videos_interface,
        inputs=proc_inputs,
        outputs=[status_output, output_files_display, preview_output] # Pass None to preview output
    )

    gr.Markdown("---")
    gr.Markdown(f"**æç¤º:** å¤„ç†å¤šä¸ªæˆ–é•¿è§†é¢‘æ—¶ï¼Œå°†è‡ªåŠ¨ä½¿ç”¨å¤šæ ¸ CPU åŠ é€Ÿã€‚ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ã€‚é»˜è®¤å­—ä½“ '{DEFAULT_FONT_PATH}' {'å­˜åœ¨' if default_font_exists else 'æœªæ‰¾åˆ°'}ã€‚")


# Launch the Gradio app
if __name__ == "__main__":
     # Required for multiprocessing pool to work correctly on some OS (like Windows)
    multiprocessing.freeze_support()

    if not default_font_exists:
        print(f"è­¦å‘Š: é»˜è®¤å­—ä½“ '{DEFAULT_FONT_PATH}' æœªæ‰¾åˆ°ã€‚")
        print("é™¤éé€šè¿‡ç•Œé¢ä¸Šä¼ å­—ä½“æ–‡ä»¶ï¼Œå¦åˆ™æ–‡æœ¬æ°´å°åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œæˆ–æ˜¾ç¤ºå¼‚å¸¸ã€‚")

    print(f"ç³»ç»Ÿ CPU æ ¸å¿ƒæ•°: {os.cpu_count()}")
    print("æ­£åœ¨å¯åŠ¨ Gradio ç•Œé¢...")
    demo.launch()