# -*- coding: utf-8 -*- # Add this for better encoding support
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import gradio as gr
import os
import time
import math
import random

# --- Configuration ---
# IMPORTANT: Replace with a valid path to a font file that supports Chinese characters if needed
# Or instruct users clearly they MUST upload one for Chinese text.
# SimHei is common on Windows, Arial Unicode MS, or Noto Sans CJK are good alternatives.
# Let's assume a generic name, user MUST provide if default doesn't exist/work.
DEFAULT_FONT_PATH = "msyh.ttc" # Example: Microsoft YaHei path (adjust for your system or use upload)
DEFAULT_OUTPUT_DIR = "output_videos"

# --- Helper Functions ---

def hex_to_rgba(hex_color, alpha=255):
    """
    Converts hex color string (#RRGGBB or #RGB) to (R, G, B, A) tuple.
    The 'alpha' parameter (0-255) determines the final transparency.
    """
    if not hex_color:
        # Default to white if color is empty
        print("Warning: Color is empty, defaulting to white.")
        hex_color = "#FFFFFF"
        # raise ValueError("é¢œè‰²ä¸èƒ½ä¸ºç©º") # Original Chinese error

    hex_input = hex_color.lstrip('#')

    # Validate hex characters
    if not all(c in '0123456789ABCDEFabcdef' for c in hex_input):
         # Fallback for invalid hex? Default to white?
         print(f"è­¦å‘Šï¼šæ— æ•ˆçš„åå…­è¿›åˆ¶é¢œè‰²å­—ç¬¦: {hex_color}ï¼Œå°†ä½¿ç”¨ç™½è‰²ã€‚")
         hex_input = "FFFFFF"
         # raise ValueError(f"æ— æ•ˆçš„åå…­è¿›åˆ¶é¢œè‰²å­—ç¬¦ (å¿…é¡»æ˜¯ 0-9, A-F): {hex_color}") # Original error

    # Validate hex length
    if len(hex_input) == 3:
        hex_input = ''.join([c*2 for c in hex_input])
    elif len(hex_input) != 6:
         # Fallback for invalid length? Default to white?
         print(f"è­¦å‘Šï¼šæ— æ•ˆçš„åå…­è¿›åˆ¶é¢œè‰²é•¿åº¦ (å¿…é¡»æ˜¯ 3 æˆ– 6 ä½): #{hex_input}ï¼Œå°†ä½¿ç”¨ç™½è‰²ã€‚")
         hex_input = "FFFFFF"
        # raise ValueError(f"æ— æ•ˆçš„åå…­è¿›åˆ¶é¢œè‰²é•¿åº¦ (å¿…é¡»æ˜¯ 3 æˆ– 6 ä¸ªå­—ç¬¦): {hex_color}") # Original error

    try:
        r = int(hex_input[0:2], 16)
        g = int(hex_input[2:4], 16)
        b = int(hex_input[4:6], 16)
    except ValueError:
        # Handle potential conversion errors if validation somehow failed
        print(f"é”™è¯¯: è½¬æ¢åå…­è¿›åˆ¶é¢œè‰²å¤±è´¥: {hex_color}ï¼Œå°†ä½¿ç”¨ç™½è‰²ã€‚")
        r, g, b = 255, 255, 255

    # Ensure alpha is within valid range
    final_alpha = max(0, min(255, int(alpha)))

    return (r, g, b, final_alpha)

def apply_opacity(img, opacity_percent):
    """Applies overall opacity to a PIL image (RGBA)."""
    if img.mode != 'RGBA':
        img = img.convert('RGBA')
    alpha = img.split()[3]
    # Adjust alpha: Scale existing alpha by the desired opacity percentage.
    # Ensure calculations use floats and result is clamped 0-255.
    opacity_factor = max(0.0, min(1.0, opacity_percent / 100.0))
    alpha = alpha.point(lambda p: max(0, min(255, int(p * opacity_factor))))
    img.putalpha(alpha)
    return img

# --- Watermark Generation ---

def create_text_watermark(text, font_path, font_size, color_hex, opacity_percent):
    """Creates a transparent PIL image with the specified text and opacity."""
    try:
        # Use default if path is None, empty, or doesn't exist and DEFAULT exists
        if not font_path or not os.path.exists(font_path):
             if os.path.exists(DEFAULT_FONT_PATH):
                 print(f"è­¦å‘Š: å­—ä½“æ–‡ä»¶ '{font_path}' æœªæ‰¾åˆ°æˆ–æœªæä¾›ã€‚ä½¿ç”¨é»˜è®¤å­—ä½“: {DEFAULT_FONT_PATH}")
                 font_path = DEFAULT_FONT_PATH
             else:
                 print(f"é”™è¯¯: å­—ä½“æ–‡ä»¶ '{font_path}' åŠé»˜è®¤å­—ä½“ '{DEFAULT_FONT_PATH}' å‡æœªæ‰¾åˆ°ã€‚")
                 raise ValueError(f"æœªæ‰¾åˆ°å­—ä½“æ–‡ä»¶ '{font_path}' æˆ–é»˜è®¤å­—ä½“ '{DEFAULT_FONT_PATH}'ã€‚è¯·ä¸Šä¼ å­—ä½“æˆ–ç¡®ä¿é»˜è®¤å­—ä½“è·¯å¾„æœ‰æ•ˆã€‚")
        font = ImageFont.truetype(font_path, font_size)
        print(f"ä½¿ç”¨å­—ä½“: {font_path}")
    except IOError as e:
        print(f"é”™è¯¯: åŠ è½½å­—ä½“æ–‡ä»¶æ—¶å‡ºé”™ {font_path}: {e}ã€‚å°è¯• Pillow é»˜è®¤å­—ä½“ã€‚")
        try:
            font = ImageFont.load_default() # Very basic, likely no Chinese support
        except Exception as e_def:
             raise ValueError(f"æ— æ³•åŠ è½½æŒ‡å®šå­—ä½“ '{font_path}' æˆ– Pillow é»˜è®¤å­—ä½“ã€‚è¯·æä¾›æœ‰æ•ˆçš„ .ttf æˆ– .otf æ–‡ä»¶ã€‚é”™è¯¯: {e_def}")

    # Calculate text bounding box using the loaded font
    try:
        # Use getbbox for more accurate size calculation
        text_bbox = font.getbbox(text)
        # text_bbox is (left, top, right, bottom) relative to baseline origin (0,0)
        text_width = text_bbox[2] - text_bbox[0]
        text_height = text_bbox[3] - text_bbox[1]
        
        # Handle potential negative 'top' (descenders going below baseline)
        offset_y = -text_bbox[1] # Amount the text starts above the origin
        
        # Add padding for safety, especially around edges
        padding = 5
        img_width = text_width + 2 * padding
        img_height = text_height + 2 * padding

        # Create image: Use 0 alpha for transparent background
        img = Image.new('RGBA', (img_width, img_height), (255, 255, 255, 0))
        draw = ImageDraw.Draw(img)

        # Calculate color with desired base alpha (opacity)
        base_alpha = int(255 * (opacity_percent / 100.0)) # Opacity applies to the solid color
        text_color_rgba = hex_to_rgba(color_hex, alpha=base_alpha)

        # Draw text slightly offset within the padded area
        # Draw at (padding, padding + offset_y)
        draw.text((padding, padding + offset_y), text, font=font, fill=text_color_rgba)

        # Crop to the actual content bounds
        try:
             bbox = img.getbbox() # Find the boundary of non-transparent pixels
             if bbox:
                # Crop using the calculated bounding box
                img = img.crop(bbox)
             else: # Handle case where text might be empty or render fully transparent
                img = Image.new('RGBA', (1, 1), (255, 255, 255, 0)) # Minimal transparent image
        except Exception as crop_e:
             print(f"è­¦å‘Š: è£å‰ªæ–‡æœ¬æ°´å°æ—¶å‡ºé”™: {crop_e}. ä½¿ç”¨æœªè£å‰ªå›¾åƒã€‚")
             pass # Keep the padded image if cropping fails

        # Double check size, ensure > 0
        if img.width <= 0 or img.height <= 0:
             print("è­¦å‘Š: åˆ›å»ºçš„æ–‡æœ¬æ°´å°å°ºå¯¸ä¸ºé›¶æˆ–è´Ÿæ•°ï¼Œå°†ä½¿ç”¨1x1é€æ˜åƒç´ ã€‚")
             img = Image.new('RGBA', (1, 1), (255, 255, 255, 0))

        return img

    except Exception as e:
        print(f"é”™è¯¯: åˆ›å»ºæ–‡æœ¬æ°´å°æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        # Fallback to a minimal transparent image on error
        return Image.new('RGBA', (10, 10), (255, 255, 255, 0))


def load_image_watermark(image_path, scale_percent, frame_width, frame_height, opacity_percent):
    """Loads, scales, and applies opacity to an image watermark."""
    if not image_path or not os.path.exists(image_path):
         raise ValueError(f"å›¾ç‰‡æ°´å°æ–‡ä»¶æœªæ‰¾åˆ°æˆ–æ— æ•ˆ: {image_path}")
    try:
        img = Image.open(image_path).convert("RGBA")
    except Exception as e:
        raise ValueError(f"æ‰“å¼€å›¾ç‰‡æ°´å°æ—¶å‡ºé”™ {image_path}: {e}")

    # --- Scaling ---
    # Scale based on frame dimension and percentage
    base_dimension = max(frame_width, frame_height) # Scale relative to largest dimension
    target_width = int(base_dimension * (scale_percent / 100.0))

    # Calculate new height maintaining aspect ratio
    if img.width > 0:
        img_ratio = img.height / img.width
        target_height = int(target_width * img_ratio)
    else:
        target_height = int(base_dimension * (scale_percent / 100.0)) # Default if width is 0

    # Ensure target dimensions are at least 1x1
    target_width = max(1, target_width)
    target_height = max(1, target_height)

    # Resize using Pillow's high-quality downsampling filter
    try:
        img = img.resize((target_width, target_height), Image.Resampling.LANCZOS)
    except AttributeError: # Handle older Pillow versions
         print("è­¦å‘Š: Pillow ç‰ˆæœ¬è¾ƒæ—§ï¼Œä½¿ç”¨ ANTIALIAS è¿›è¡Œç¼©æ”¾ã€‚")
         img = img.resize((target_width, target_height), Image.ANTIALIAS)
    except Exception as resize_e:
         raise ValueError(f"ç¼©æ”¾å›¾ç‰‡æ°´å°æ—¶å‡ºé”™: {resize_e}")


    # --- Apply Opacity ---
    img = apply_opacity(img, opacity_percent)

    return img

# --- Motion Calculation (WatermarkMover class remains largely the same) ---
class WatermarkMover:
    """è®¡ç®—æ°´å°ä½ç½®åŸºäºé€‰å®šçš„è·¯å¾„å’ŒåŒºåŸŸã€‚"""
    def __init__(self, path_type, frame_width, frame_height, watermark_width, watermark_height, margin_percent, speed_factor):
        self.path_type = path_type
        self.speed_factor = max(0.1, speed_factor) # ç¡®ä¿æœ€å°é€Ÿåº¦

        # Define motion boundaries based on margin
        margin_x = int(frame_width * (margin_percent / 100.0))
        margin_y = int(frame_height * (margin_percent / 100.0))

        self.min_x = margin_x
        self.min_y = margin_y
        # Adjust max bounds so the *entire* watermark stays within margin
        self.max_x = frame_width - margin_x - watermark_width
        self.max_y = frame_height - margin_y - watermark_height

        # Ensure bounds are valid (watermark isn't larger than allowed area)
        self.max_x = max(self.min_x, self.max_x)
        self.max_y = max(self.min_y, self.max_y)

        self.frame_width = frame_width
        self.frame_height = frame_height
        self.watermark_width = watermark_width
        self.watermark_height = watermark_height
        self.margin_percent = margin_percent # Store for potential re-init

        # Initial state for dynamic paths
        self.x = random.randint(self.min_x, self.max_x) if self.max_x > self.min_x else self.min_x
        self.y = random.randint(self.min_y, self.max_y) if self.max_y > self.min_y else self.min_y

        # Base speed (pixels per frame), adjust with speed_factor
        base_speed_x = max(1, int(frame_width * 0.005 * self.speed_factor))
        base_speed_y = max(1, int(frame_height * 0.005 * self.speed_factor))

        self.dx = random.choice([-base_speed_x, base_speed_x]) if base_speed_x > 0 else 0
        self.dy = random.choice([-base_speed_y, base_speed_y]) if base_speed_y > 0 else 0
        
        # Ensure dx/dy are not both zero if bounds allow movement
        if self.dx == 0 and self.dy == 0 and (self.max_x > self.min_x or self.max_y > self.min_y):
             self.dx = base_speed_x if self.max_x > self.min_x else 0
             self.dy = base_speed_y if self.max_y > self.min_y and self.dx == 0 else 0 # Prefer horizontal if possible

        # Static position (center)
        self.static_x = max(0, (frame_width - watermark_width) // 2)
        self.static_y = max(0, (frame_height - watermark_height) // 2)


    def get_position(self, frame_index, total_frames):
        """è®¡ç®—å½“å‰å¸§çš„ä½ç½®ã€‚"""
        if self.path_type == "é™æ€å±…ä¸­":
            return self.static_x, self.static_y

        elif self.path_type == "è¾¹æ¡†åå¼¹":
            # Prevent movement if bounds are collapsed
            if self.max_x <= self.min_x: self.dx = 0
            if self.max_y <= self.min_y: self.dy = 0

            self.x += self.dx
            self.y += self.dy

            # Bounce off edges
            bounced = False
            if self.x <= self.min_x:
                self.x = self.min_x
                self.dx = abs(self.dx) if self.dx != 0 else (random.choice([1,-1]) if self.max_x > self.min_x else 0) # Introduce randomness if stuck
                bounced = True
            elif self.x >= self.max_x:
                self.x = self.max_x
                self.dx = -abs(self.dx) if self.dx != 0 else (random.choice([1,-1]) if self.max_x > self.min_x else 0)
                bounced = True

            if self.y <= self.min_y:
                self.y = self.min_y
                self.dy = abs(self.dy) if self.dy != 0 else (random.choice([1,-1]) if self.max_y > self.min_y else 0)
                bounced = True
            elif self.y >= self.max_y:
                self.y = self.max_y
                self.dy = -abs(self.dy) if self.dy != 0 else (random.choice([1,-1]) if self.max_y > self.min_y else 0)
                bounced = True

            # Ensure position stays within bounds if speed is high
            self.x = max(self.min_x, min(self.x, self.max_x))
            self.y = max(self.min_y, min(self.y, self.max_y))

            return int(self.x), int(self.y)

        elif self.path_type == "æ°´å¹³ç§»åŠ¨":
            # Simple back and forth horizontally
            if total_frames <= 0: total_frames = 1 # Avoid division by zero
            progress = (frame_index % total_frames) / total_frames # Cycle progress
            amplitude = (self.max_x - self.min_x) / 2
            center_x = self.min_x + amplitude
            # Use sine wave for smooth oscillation, adjust frequency with speed
            frequency = 1.0 * self.speed_factor # Base cycles per video * speed factor
            current_x = center_x + amplitude * math.sin(2 * math.pi * frequency * progress)
            # Fixed vertical position (center of allowed area)
            current_y = self.min_y + (self.max_y - self.min_y) / 2

            # Ensure within bounds
            current_x = max(self.min_x, min(current_x, self.max_x))
            current_y = max(self.min_y, min(current_y, self.max_y))

            return int(current_x), int(current_y)

        elif self.path_type == "å‚ç›´ç§»åŠ¨":
            # Simple back and forth vertically
            if total_frames <= 0: total_frames = 1
            progress = (frame_index % total_frames) / total_frames
            amplitude = (self.max_y - self.min_y) / 2
            center_y = self.min_y + amplitude
            frequency = 1.0 * self.speed_factor
            current_y = center_y + amplitude * math.sin(2 * math.pi * frequency * progress)
            # Fixed horizontal position (center of allowed area)
            current_x = self.min_x + (self.max_x - self.min_x) / 2

            # Ensure within bounds
            current_x = max(self.min_x, min(current_x, self.max_x))
            current_y = max(self.min_y, min(current_y, self.max_y))

            return int(current_x), int(current_y)

        else: # Default to static if path unknown
            print(f"è­¦å‘Š: æœªçŸ¥çš„ç§»åŠ¨è·¯å¾„ '{self.path_type}'ï¼Œå°†ä½¿ç”¨é™æ€å±…ä¸­ã€‚")
            return self.static_x, self.static_y

# --- Core Video Processing ---

def add_watermark_to_video(input_video_path, output_video_path, watermark_pil, mover, progress=gr.Progress()):
    """å°†å‡†å¤‡å¥½çš„æ°´å° PIL å›¾åƒæ·»åŠ åˆ°è§†é¢‘çš„æ¯ä¸€å¸§ã€‚"""
    cap = cv2.VideoCapture(input_video_path)
    if not cap.isOpened():
        raise IOError(f"é”™è¯¯: æ‰“å¼€è§†é¢‘æ–‡ä»¶å¤±è´¥: {input_video_path}")

    # Get video properties
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # Validate properties
    if not all([fps > 0, frame_width > 0, frame_height > 0, total_frames >= 0]): # total_frames can be 0 for streams
         cap.release()
         raise ValueError(f"è§†é¢‘å±æ€§æ— æ•ˆæˆ–æ— æ³•è¯»å–: FPS={fps}, å®½åº¦={frame_width}, é«˜åº¦={frame_height}, æ€»å¸§æ•°={total_frames}")

    # Ensure watermark fits within the frame (can happen if margin is 0 and watermark is large)
    if watermark_pil.width > frame_width or watermark_pil.height > frame_height:
         print(f"è­¦å‘Š: æ°´å°å°ºå¯¸ ({watermark_pil.width}x{watermark_pil.height}) è¶…å‡ºå¸§å°ºå¯¸ ({frame_width}x{frame_height})ã€‚å°†è°ƒæ•´æ°´å°å¤§å°ä»¥é€‚åº”ã€‚")
         # Resize watermark to fit frame while maintaining aspect ratio
         ratio = min(frame_width / watermark_pil.width, frame_height / watermark_pil.height)
         new_w = max(1, int(watermark_pil.width * ratio))
         new_h = max(1, int(watermark_pil.height * ratio))
         try:
            print(f"  è°ƒæ•´æ°´å°å¤§å°ä¸º: {new_w}x{new_h}")
            watermark_pil = watermark_pil.resize((new_w, new_h), Image.Resampling.LANCZOS)
         except AttributeError:
            watermark_pil = watermark_pil.resize((new_w, new_h), Image.ANTIALIAS)
         except Exception as resize_err:
             print(f"  è°ƒæ•´æ°´å°å¤§å°æ—¶å‡ºé”™: {resize_err}. ç»§ç»­ä½¿ç”¨åŸå§‹ï¼ˆå¯èƒ½è£å‰ªçš„ï¼‰æ°´å°ã€‚")
             # Keep original watermark_pil but it might get clipped.

         # Re-initialize mover with new watermark dimensions as bounds depend on it
         print("ç”±äºæ°´å°å°ºå¯¸è°ƒæ•´ï¼Œé‡æ–°åˆå§‹åŒ–æ°´å°ç§»åŠ¨å™¨ã€‚")
         # Need mover's original parameters
         mover.__init__(mover.path_type, frame_width, frame_height, new_w, new_h, mover.margin_percent, mover.speed_factor)


    # Define the codec and create VideoWriter object
    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Common codec for .mp4
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))
    if not out.isOpened():
        cap.release()
        raise IOError(f"é”™è¯¯: æ— æ³•åˆ›å»ºè¾“å‡ºè§†é¢‘æ–‡ä»¶: {output_video_path}. æ£€æŸ¥ç¼–è§£ç å™¨æˆ–è·¯å¾„æƒé™ã€‚")

    frame_count = 0
    start_time = time.time()

    # Initialize progress tracking for Gradio
    progress(0, desc=f"å¼€å§‹å¤„ç† {os.path.basename(input_video_path)}")

    while True:
        ret, frame_bgr = cap.read()
        if not ret:
            break # End of video or error reading frame

        # --- Apply watermark using Pillow ---
        # 1. Convert OpenCV frame (BGR) to PIL image (RGBA) for compositing
        try:
            frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
            pil_frame = Image.fromarray(frame_rgb).convert("RGBA")
        except Exception as convert_e:
            print(f"é”™è¯¯: åœ¨å¸§ {frame_count} è½¬æ¢ BGR åˆ° RGBA å¤±è´¥: {convert_e}. è·³è¿‡æ­¤å¸§æ°´å°ã€‚")
            out.write(frame_bgr) # Write original frame on error
            frame_count += 1
            continue


        # 2. Get watermark position for this frame
        wm_x, wm_y = mover.get_position(frame_count, total_frames if total_frames > 0 else 1) # Avoid zero total_frames in mover

        # Ensure position is integer and clamped
        wm_x = max(0, min(int(wm_x), frame_width - watermark_pil.width))
        wm_y = max(0, min(int(wm_y), frame_height - watermark_pil.height))

        # 3. Paste watermark onto the frame using alpha compositing
        try:
            # Create a temporary RGBA layer for pasting, same size as frame, fully transparent
            # This seems unnecessary if pil_frame is already RGBA. Let's composite directly.
            # rgba_layer = Image.new('RGBA', pil_frame.size, (0,0,0,0))
            # rgba_layer.paste(watermark_pil, (wm_x, wm_y), mask=watermark_pil) # Use watermark alpha as mask
            # pil_frame_out = Image.alpha_composite(pil_frame, rgba_layer)

            # Simpler approach: Create a copy to paste onto if needed, or paste directly
            # Check if watermark has actual content (alpha > 0)
            if watermark_pil.getextrema()[3][0] < 255: # Check if any pixel is not fully transparent
                 # Create a transparent overlay the size of the frame
                 overlay = Image.new('RGBA', pil_frame.size, (255, 255, 255, 0))
                 # Paste the watermark onto the overlay
                 overlay.paste(watermark_pil, (wm_x, wm_y), mask=watermark_pil)
                 # Composite the overlay (with watermark) onto the frame
                 pil_frame_out = Image.alpha_composite(pil_frame, overlay)
            else:
                 # Watermark seems fully transparent, skip compositing
                 pil_frame_out = pil_frame

        except Exception as e:
            print(f"é”™è¯¯: åœ¨å¸§ {frame_count} ç²˜è´´æ°´å°æ—¶å‡ºé”™: {e}. ä½ç½®:({wm_x},{wm_y}), æ°´å°å°ºå¯¸: {watermark_pil.size}, å¸§å°ºå¯¸: {pil_frame.size}. è·³è¿‡æ­¤å¸§æ°´å°ã€‚")
            pil_frame_out = pil_frame # Skip pasting on error for this frame


        # 4. Convert PIL image (RGBA) back to OpenCV frame (BGR)
        try:
            # Need to convert back to RGB first before converting color space
            pil_frame_out_rgb = pil_frame_out.convert("RGB")
            frame_out_bgr = cv2.cvtColor(np.array(pil_frame_out_rgb), cv2.COLOR_RGB2BGR)
        except Exception as convert_back_e:
             print(f"é”™è¯¯: åœ¨å¸§ {frame_count} è½¬æ¢ RGBA å› BGR å¤±è´¥: {convert_back_e}. è·³è¿‡æ­¤å¸§ã€‚")
             # Decide how to handle: write original? skip frame?
             # Let's write the original BGR frame to avoid losing frames
             out.write(frame_bgr)
             frame_count += 1
             continue

        # --- Write the frame ---
        out.write(frame_out_bgr)

        frame_count += 1
        # Update Gradio progress
        if total_frames > 0:
             progress(frame_count / total_frames, desc=f"å¤„ç†ä¸­ {frame_count}/{total_frames}")
        else:
             # Estimate progress based on time for streams? Or just show frame count.
             if frame_count % 30 == 0: # Update every second assuming ~30fps
                 elapsed = time.time() - start_time
                 progress(frame_count / (frame_count + 1), desc=f"å¤„ç†ä¸­: {frame_count} å¸§, {elapsed:.1f} ç§’")


    # Release everything
    cap.release()
    out.release()
    # cv2.destroyAllWindows() # Not needed in script context

    end_time = time.time()
    duration = end_time - start_time
    print(f"å®Œæˆå¤„ç† {input_video_path}ã€‚è€—æ—¶: {duration:.2f} ç§’")
    progress(1.0, desc=f"å®Œæˆ {os.path.basename(input_video_path)}") # Final progress update


# --- Gradio Interface Function ---

def process_videos_interface(
    input_videos, # List of file paths from gr.Files
    watermark_type,
    text_content,
    font_file, # File object from gr.File
    font_size,
    text_color,
    image_file, # File object from gr.File
    image_scale,
    watermark_opacity, # Added opacity parameter
    motion_path,
    motion_margin,
    motion_speed,
    output_dir_name,
    progress=gr.Progress(track_tqdm=True)): # Add progress tracking

    if not input_videos:
        return "é”™è¯¯: æœªé€‰æ‹©ä»»ä½•è¾“å…¥è§†é¢‘æ–‡ä»¶ã€‚", [], None # Added None for preview output

    # Create output directory
    output_base = output_dir_name if output_dir_name else DEFAULT_OUTPUT_DIR
    if not os.path.exists(output_base):
        try:
            os.makedirs(output_base)
            print(f"åˆ›å»ºè¾“å‡ºç›®å½•: {output_base}")
        except OSError as e:
            return f"é”™è¯¯: æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½• '{output_base}': {e}", [], None

    status_messages = []
    output_file_paths = []

    # --- Font File Handling ---
    final_font_path = None
    if watermark_type == "æ–‡æœ¬":
        if font_file is not None:
            # Gradio File component gives a TemporaryFile object with a .name attribute for path
            final_font_path = font_file.name
            status_messages.append(f"ä½¿ç”¨ä¸Šä¼ çš„å­—ä½“: {os.path.basename(final_font_path)}")
            if not os.path.exists(final_font_path):
                 status_messages.append(f"è­¦å‘Š: ä¸Šä¼ çš„å­—ä½“æ–‡ä»¶è·¯å¾„ '{final_font_path}' ä¼¼ä¹æ— æ•ˆã€‚å°è¯•ä½¿ç”¨é»˜è®¤å­—ä½“ã€‚")
                 final_font_path = None # Fallback to check default
        else:
            status_messages.append(f"æœªæä¾›å­—ä½“æ–‡ä»¶ã€‚å°è¯•ä½¿ç”¨é»˜è®¤å­—ä½“: {DEFAULT_FONT_PATH}")

        # If no specific font path or it was invalid, try the default
        if final_font_path is None:
             if os.path.exists(DEFAULT_FONT_PATH):
                 final_font_path = DEFAULT_FONT_PATH
                 status_messages.append(f"ä½¿ç”¨é»˜è®¤å­—ä½“: {DEFAULT_FONT_PATH}")
             else:
                 error_msg = f"é”™è¯¯: æ–‡æœ¬æ°´å°éœ€è¦å­—ä½“ï¼Œä½†æ—¢æœªæä¾›æœ‰æ•ˆå­—ä½“ï¼Œä¹Ÿæ‰¾ä¸åˆ°é»˜è®¤å­—ä½“ '{DEFAULT_FONT_PATH}'ã€‚"
                 status_messages.append(error_msg)
                 return "\n".join(status_messages), [], None

    # --- Image File Handling ---
    image_watermark_path = None
    if watermark_type == "å›¾ç‰‡":
        if image_file is not None:
            image_watermark_path = image_file.name
            status_messages.append(f"ä½¿ç”¨ä¸Šä¼ çš„å›¾ç‰‡: {os.path.basename(image_watermark_path)}")
            if not os.path.exists(image_watermark_path):
                 status_messages.append(f"é”™è¯¯: ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶è·¯å¾„ '{image_watermark_path}' ä¼¼ä¹æ— æ•ˆã€‚")
                 return "\n".join(status_messages), [], None
        else:
             status_messages.append(f"é”™è¯¯: é€‰æ‹©äº†å›¾ç‰‡æ°´å°ç±»å‹ï¼Œä½†æœªæä¾›å›¾ç‰‡æ–‡ä»¶ã€‚")
             return "\n".join(status_messages), [], None


    # --- Process Each Video ---
    total_videos = len(input_videos)
    for i, video_file in enumerate(input_videos):
        input_path = video_file.name # Path from Gradio's TemporaryFile object
        base_filename = os.path.basename(input_path)
        filename_no_ext, _ = os.path.splitext(base_filename)
        # Sanitize filename slightly (replace spaces, etc.) if needed
        safe_filename = "".join(c if c.isalnum() or c in ('_', '-') else '_' for c in filename_no_ext)
        output_filename = f"{safe_filename}_watermarked.mp4"
        output_path = os.path.join(output_base, output_filename)

        status_messages.append(f"\n[{i+1}/{total_videos}] å¼€å§‹å¤„ç†: {base_filename} -> {output_filename}")
        print(f"å¼€å§‹å¤„ç†è§†é¢‘ {i+1}/{total_videos}: {input_path}")

        try:
            # --- Get Video Dimensions for Watermark Prep ---
            temp_cap = cv2.VideoCapture(input_path)
            if not temp_cap.isOpened():
                raise IOError(f"æ— æ³•æ‰“å¼€è§†é¢‘ '{base_filename}' ä»¥è·å–å°ºå¯¸ã€‚")
            vid_width = int(temp_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            vid_height = int(temp_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            total_vid_frames = int(temp_cap.get(cv2.CAP_PROP_FRAME_COUNT)) # For mover
            temp_cap.release()

            if vid_width <= 0 or vid_height <= 0:
                 raise ValueError(f"è·å–åˆ°çš„è§†é¢‘å°ºå¯¸æ— æ•ˆ: {vid_width}x{vid_height}")

            # --- Prepare Watermark (Specific to this video's dimensions) ---
            watermark_pil = None
            if watermark_type == "æ–‡æœ¬":
                status_messages.append(f"  åˆ›å»ºæ–‡æœ¬æ°´å°: '{text_content[:30]}...' å°ºå¯¸:{font_size}pt é€æ˜åº¦:{watermark_opacity}%")
                watermark_pil = create_text_watermark(
                    text_content, final_font_path, font_size, text_color, watermark_opacity
                )
            elif watermark_type == "å›¾ç‰‡":
                 status_messages.append(f"  åŠ è½½å›¾ç‰‡æ°´å°: ç¼©æ”¾:{image_scale}% é€æ˜åº¦:{watermark_opacity}%")
                 watermark_pil = load_image_watermark(
                    image_watermark_path, image_scale, vid_width, vid_height, watermark_opacity
                 )
            else:
                # This case should not be reachable if UI is set up correctly
                raise ValueError(f"å†…éƒ¨é”™è¯¯ï¼šæœªçŸ¥çš„æ°´å°ç±»å‹ '{watermark_type}'")

            if watermark_pil is None or watermark_pil.width <= 0 or watermark_pil.height <= 0:
                raise ValueError("æ°´å°åˆ›å»ºå¤±è´¥æˆ–å°ºå¯¸æ— æ•ˆã€‚")
            status_messages.append(f"  æ°´å°å·²ç”Ÿæˆï¼Œå°ºå¯¸: {watermark_pil.width}x{watermark_pil.height}")

            # --- Initialize Mover ---
            mover = WatermarkMover(
                path_type=motion_path,
                frame_width=vid_width,
                frame_height=vid_height,
                watermark_width=watermark_pil.width,
                watermark_height=watermark_pil.height,
                margin_percent=motion_margin,
                speed_factor=motion_speed
            )
            status_messages.append(f"  åˆå§‹åŒ–ç§»åŠ¨å™¨: ç±»å‹:{motion_path}, è¾¹è·:{motion_margin}%, é€Ÿåº¦:{motion_speed}x")

            # --- Add Watermark to Video ---
            add_watermark_to_video(input_path, output_path, watermark_pil, mover, progress)

            status_messages.append(f"  æˆåŠŸå¤„ç†å¹¶ä¿å­˜åˆ°: {output_path}")
            output_file_paths.append(output_path)

        except Exception as e:
            error_msg = f"  é”™è¯¯ å¤„ç† {base_filename} æ—¶å‘ç”Ÿé”™è¯¯: {type(e).__name__}: {e}"
            print(error_msg) # Print detailed error to console
            status_messages.append(error_msg)
            # Clean up partially created output file if it exists
            if os.path.exists(output_path):
                 try:
                     os.remove(output_path)
                     status_messages.append(f"  å·²åˆ é™¤éƒ¨åˆ†ç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶: {output_path}")
                 except OSError as rm_err:
                     status_messages.append(f"  è­¦å‘Š: æ— æ³•åˆ é™¤éƒ¨åˆ†æ–‡ä»¶ {output_path}: {rm_err}")

    status_messages.append("\næ‰¹é‡å¤„ç†å®Œæˆã€‚")
    # Return status log and list of output file paths
    return "\n".join(status_messages), output_file_paths, None # No preview update from main process


# --- Preview Function ---
def generate_preview(
    input_videos, # Need this to get a frame
    watermark_type,
    text_content,
    font_file,
    font_size,
    text_color,
    image_file,
    image_scale,
    watermark_opacity,
    motion_path,
    motion_margin,
    motion_speed):

    if not input_videos:
        # Return a placeholder or message image if no video selected
        # Create a simple black image with text
        img = Image.new('RGB', (300, 100), color = 'black')
        d = ImageDraw.Draw(img)
        try:
            # Try using a basic font if available
            font = ImageFont.truetype("arial.ttf", 15) # Adjust path/size if needed
        except IOError:
            font = ImageFont.load_default()
        d.text((10,10), "è¯·å…ˆä¸Šä¼ ä¸€ä¸ªè§†é¢‘æ–‡ä»¶\næ‰èƒ½ç”Ÿæˆé¢„è§ˆ", fill='white', font=font)
        return img # Return PIL image directly

    preview_status = ""
    try:
        input_path = input_videos[0].name # Use the first video
        preview_status += f"ä½¿ç”¨è§†é¢‘ '{os.path.basename(input_path)}' çš„ç¬¬ä¸€å¸§è¿›è¡Œé¢„è§ˆã€‚\n"

        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            raise IOError(f"æ— æ³•æ‰“å¼€è§†é¢‘ '{os.path.basename(input_path)}' è¿›è¡Œé¢„è§ˆã€‚")

        # Read the first frame (or maybe a few frames in?)
        frame_to_preview = 10 # Try frame 10 to skip potential black intro
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_to_preview)
        ret, frame_bgr = cap.read()
        if not ret:
             # If frame 10 fails, try frame 0
             cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
             ret, frame_bgr = cap.read()
             if not ret:
                 raise ValueError("æ— æ³•è¯»å–è§†é¢‘å¸§è¿›è¡Œé¢„è§ˆã€‚")
             frame_to_preview = 0 # Used frame 0

        vid_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        vid_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # Needed for mover % calc
        cap.release()

        if vid_width <= 0 or vid_height <= 0:
            raise ValueError("é¢„è§ˆæ—¶è·å–çš„è§†é¢‘å°ºå¯¸æ— æ•ˆã€‚")

        # --- Prepare Watermark using current settings ---
        watermark_pil = None
        final_font_path_preview = None # Separate font path logic for preview
        if watermark_type == "æ–‡æœ¬":
            if font_file is not None:
                 final_font_path_preview = font_file.name
                 if not os.path.exists(final_font_path_preview): final_font_path_preview = None
            if final_font_path_preview is None and os.path.exists(DEFAULT_FONT_PATH):
                 final_font_path_preview = DEFAULT_FONT_PATH
            if final_font_path_preview is None:
                 raise ValueError("é¢„è§ˆéœ€è¦å­—ä½“ï¼Œä½†æœªæä¾›æˆ–æ‰¾ä¸åˆ°é»˜è®¤å­—ä½“ã€‚")

            watermark_pil = create_text_watermark(
                text_content, final_font_path_preview, font_size, text_color, watermark_opacity
            )
            preview_status += f"åˆ›å»ºæ–‡æœ¬æ°´å° (å­—ä½“: {os.path.basename(final_font_path_preview)}, å°ºå¯¸: {font_size}pt, é€æ˜åº¦: {watermark_opacity}%)\n"

        elif watermark_type == "å›¾ç‰‡":
            if image_file is None or not os.path.exists(image_file.name):
                raise ValueError("é¢„è§ˆéœ€è¦å›¾ç‰‡ï¼Œä½†æœªæä¾›æˆ–æ–‡ä»¶æ— æ•ˆã€‚")
            image_watermark_path_preview = image_file.name
            watermark_pil = load_image_watermark(
                image_watermark_path_preview, image_scale, vid_width, vid_height, watermark_opacity
            )
            preview_status += f"åŠ è½½å›¾ç‰‡æ°´å° (æ–‡ä»¶: {os.path.basename(image_watermark_path_preview)}, ç¼©æ”¾: {image_scale}%, é€æ˜åº¦: {watermark_opacity}%)\n"
        else:
             raise ValueError("æ— æ•ˆçš„æ°´å°ç±»å‹ã€‚")

        if watermark_pil is None or watermark_pil.width <= 0 or watermark_pil.height <= 0:
             raise ValueError("é¢„è§ˆæ—¶æ°´å°åˆ›å»ºå¤±è´¥æˆ–å°ºå¯¸æ— æ•ˆã€‚")
        preview_status += f"æ°´å°å°ºå¯¸: {watermark_pil.width}x{watermark_pil.height}\n"

        # --- Initialize Mover ---
        mover = WatermarkMover(
            path_type=motion_path,
            frame_width=vid_width,
            frame_height=vid_height,
            watermark_width=watermark_pil.width,
            watermark_height=watermark_pil.height,
            margin_percent=motion_margin,
            speed_factor=motion_speed
        )

        # --- Get Position for the Preview Frame ---
        # Use the frame number we actually read
        wm_x, wm_y = mover.get_position(frame_to_preview, total_frames if total_frames > 0 else 1)
        wm_x = max(0, min(int(wm_x), vid_width - watermark_pil.width))
        wm_y = max(0, min(int(wm_y), vid_height - watermark_pil.height))
        preview_status += f"æ°´å°ä½ç½® (å¸§ {frame_to_preview}): ({wm_x}, {wm_y})\n"

        # --- Composite onto Frame ---
        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
        pil_frame = Image.fromarray(frame_rgb).convert("RGBA")

        # Composite (similar to add_watermark_to_video)
        if watermark_pil.getextrema()[3][0] < 255: # Check alpha channel
            overlay = Image.new('RGBA', pil_frame.size, (255, 255, 255, 0))
            overlay.paste(watermark_pil, (wm_x, wm_y), mask=watermark_pil)
            pil_frame_out = Image.alpha_composite(pil_frame, overlay)
        else:
            pil_frame_out = pil_frame

        preview_status += "é¢„è§ˆå›¾ç”ŸæˆæˆåŠŸã€‚"
        print(preview_status) # Print status to console
        return pil_frame_out.convert("RGB") # Return RGB PIL image for Gradio

    except Exception as e:
        error_msg = f"ç”Ÿæˆé¢„è§ˆæ—¶å‡ºé”™: {type(e).__name__}: {e}"
        print(error_msg)
        # Create an error image
        img = Image.new('RGB', (400, 150), color = 'darkred')
        d = ImageDraw.Draw(img)
        try: font = ImageFont.truetype("arial.ttf", 15)
        except IOError: font = ImageFont.load_default()
        d.text((10,10), f"ç”Ÿæˆé¢„è§ˆå¤±è´¥:\n{error_msg}", fill='white', font=font)
        return img


# --- Build Gradio UI (with Chinese text and new elements) ---

# Check for default font existence early
default_font_exists = os.path.exists(DEFAULT_FONT_PATH)
default_font_warning = f" (é»˜è®¤: {os.path.basename(DEFAULT_FONT_PATH)}{'' if default_font_exists else ' - æœªæ‰¾åˆ°!'})"

with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¬ è§†é¢‘æ°´å°æ·»åŠ å·¥å…·")
    gr.Markdown("ä¸ºæ‚¨çš„è§†é¢‘æ·»åŠ åŠ¨æ€æ–‡æœ¬æˆ–å›¾ç‰‡æ°´å°ï¼Œæ”¯æŒå¤šç§ç§»åŠ¨è·¯å¾„å’Œè‡ªå®šä¹‰è®¾ç½®ã€‚")

    with gr.Row():
        with gr.Column(scale=2): # Wider column for inputs
            gr.Markdown("### 1. è¾“å…¥è§†é¢‘")
            input_videos = gr.Files(label="ä¸Šä¼ è§†é¢‘æ–‡ä»¶ (å¯å¤šé€‰)", file_types=['video'], type="filepath")

            gr.Markdown("### 2. æ°´å°è®¾ç½®")
            watermark_type = gr.Radio(["æ–‡æœ¬", "å›¾ç‰‡"], label="æ°´å°ç±»å‹", value="æ–‡æœ¬")

            # --- Common Settings ---
            watermark_opacity = gr.Slider(label="æ°´å°ä¸é€æ˜åº¦ (%)", minimum=0, maximum=100, value=70, step=1)

            # --- Text Options ---
            with gr.Group(visible=True) as text_options: # Use Group for better visual separation
                gr.Markdown("#### æ–‡æœ¬æ°´å°é€‰é¡¹")
                text_content = gr.Textbox(label="æ°´å°æ–‡å­—", value="åœ¨æ­¤è¾“å…¥æ°´å°å†…å®¹", lines=2)
                font_file = gr.File(label=f"ä¸Šä¼ å­—ä½“æ–‡ä»¶ (.ttf, .otf) {default_font_warning}", file_types=['.ttf', '.otf'])
                font_size = gr.Slider(label="å­—ä½“å¤§å° (pt)", minimum=8, maximum=300, value=48, step=1)
                text_color = gr.ColorPicker(label="æ–‡å­—é¢œè‰² (Hex)", value="#FFFFFF")

            # --- Image Options ---
            with gr.Group(visible=False) as image_options: # Use Group
                 gr.Markdown("#### å›¾ç‰‡æ°´å°é€‰é¡¹")
                 image_file = gr.File(label="ä¸Šä¼ æ°´å°å›¾ç‰‡", file_types=['image'], type="filepath")
                 image_scale = gr.Slider(label="å›¾ç‰‡ç¼©æ”¾æ¯”ä¾‹ (%) - ç›¸å¯¹äºè§†é¢‘æœ€å¤§è¾¹é•¿", minimum=1, maximum=50, value=10, step=1)

            # --- Motion Settings ---
            gr.Markdown("### 3. è¿åŠ¨è®¾ç½®")
            motion_path = gr.Dropdown(
                ["é™æ€å±…ä¸­", "è¾¹æ¡†åå¼¹", "æ°´å¹³ç§»åŠ¨", "å‚ç›´ç§»åŠ¨"],
                label="æ°´å°è¿åŠ¨è·¯å¾„",
                value="è¾¹æ¡†åå¼¹"
            )
            motion_margin = gr.Slider(
                label="è¿åŠ¨åŒºåŸŸè¾¹è· (%) - æ°´å°æ´»åŠ¨èŒƒå›´è·ç¦»è§†é¢‘è¾¹ç¼˜çš„ç™¾åˆ†æ¯”",
                minimum=0, maximum=45, value=5, step=1 # Max 45% margin each side prevents overlap
            )
            motion_speed = gr.Slider(
                label="è¿åŠ¨é€Ÿåº¦å€ç‡",
                minimum=0.1, maximum=10.0, value=1.0, step=0.1
            )

            # --- Output Settings ---
            gr.Markdown("### 4. è¾“å‡ºè®¾ç½®")
            output_dir_name = gr.Textbox(label="è¾“å‡ºå­ç›®å½•åç§°", value=DEFAULT_OUTPUT_DIR)

        with gr.Column(scale=1): # Narrower column for preview and actions
            gr.Markdown("### 5. æ°´å°é¢„è§ˆ")
            preview_button = gr.Button("ç”Ÿæˆé¢„è§ˆ (ä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘)")
            preview_output = gr.Image(label="æ•ˆæœé¢„è§ˆ", type="pil", interactive=False) # Show PIL image

            gr.Markdown("### 6. å¼€å§‹å¤„ç†")
            process_button = gr.Button("å¼€å§‹æ·»åŠ æ°´å°", variant="primary")

            gr.Markdown("### çŠ¶æ€æ—¥å¿—")
            status_output = gr.Textbox(label="è¿è¡Œæ—¥å¿—", lines=15, interactive=False)

            gr.Markdown("### è¾“å‡ºæ–‡ä»¶")
            # Use gr.Files to display multiple output files for download
            output_files_display = gr.Files(label="ç”Ÿæˆçš„æ°´å°è§†é¢‘", interactive=False)


    # --- UI Logic ---
    # Visibility toggle for text/image options
    def update_visibility(choice):
        is_text = (choice == "æ–‡æœ¬")
        return {
            text_options: gr.update(visible=is_text),
            image_options: gr.update(visible=not is_text),
        }
    watermark_type.change(update_visibility, inputs=watermark_type, outputs=[text_options, image_options])

    # Gather all inputs needed for preview and processing
    all_inputs = [
            input_videos, watermark_type,
            text_content, font_file, font_size, text_color, # Text inputs
            image_file, image_scale, # Image inputs
            watermark_opacity, # Opacity input
            motion_path, motion_margin, motion_speed, # Motion inputs
            output_dir_name # Output dir (needed by main process, not preview)
    ]
    # Define inputs specifically for preview (doesn't need output_dir_name)
    preview_inputs = [
            input_videos, watermark_type,
            text_content, font_file, font_size, text_color,
            image_file, image_scale, watermark_opacity,
            motion_path, motion_margin, motion_speed
    ]

    # Connect Preview Button
    preview_button.click(
        fn=generate_preview,
        inputs=preview_inputs,
        outputs=[preview_output]
    )

    # Connect Process Button
    process_button.click(
        fn=process_videos_interface,
        inputs=all_inputs,
        outputs=[status_output, output_files_display, preview_output] # Clear preview on process start? Or keep it? Let's keep it, but pass None from process func.
    )

    gr.Markdown("---")
    gr.Markdown(f"**æ³¨æ„:** å¤„ç†é•¿è§†é¢‘å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ã€‚å¯¹äºæ–‡æœ¬æ°´å°ï¼Œå¦‚æœé»˜è®¤å­—ä½“ '{DEFAULT_FONT_PATH}' ä¸å­˜åœ¨æˆ–ä¸æ”¯æŒæ‰€éœ€å­—ç¬¦ (å¦‚ä¸­æ–‡), è¯·åŠ¡å¿…ä¸Šä¼ æ‚¨è‡ªå·±çš„å­—ä½“æ–‡ä»¶ã€‚è¾“å‡ºè§†é¢‘å°†ä¿å­˜åœ¨è„šæœ¬æ‰€åœ¨ç›®å½•ä¸‹çš„ '{DEFAULT_OUTPUT_DIR}' (æˆ–æ‚¨æŒ‡å®šçš„) å­ç›®å½•ä¸­ã€‚")


# Launch the Gradio app
if __name__ == "__main__":
    # Check default font again on startup for final warning
    if not default_font_exists:
        print(f"è­¦å‘Š: é»˜è®¤å­—ä½“ '{DEFAULT_FONT_PATH}' æœªæ‰¾åˆ°ã€‚")
        print("é™¤éé€šè¿‡ç•Œé¢ä¸Šä¼ å­—ä½“æ–‡ä»¶ï¼Œå¦åˆ™æ–‡æœ¬æ°´å°åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œæˆ–æ˜¾ç¤ºå¼‚å¸¸ã€‚")

    print("æ­£åœ¨å¯åŠ¨ Gradio ç•Œé¢...")
    # Share=True allows access over local network if needed
    demo.launch()